import React, { useRef, useEffect, useState, useCallback } from 'react';
import { Camera, AlertCircle, Play, Pause, Eye, Brain } from 'lucide-react';
import { Button, GlassCard } from './ui/LayoutComponents';
import { visionService } from '../services/visionService';
import { facialMetricsService } from '../services/facialMetricsService';
import { emotionInferenceService } from '../services/emotionInferenceService';
import { FacialMetrics, VisionAnalysisResult, EmotionState } from '../types';

export const VisionCapture: React.FC = () => {
  const videoRef = useRef<HTMLVideoElement>(null);
  const streamRef = useRef<MediaStream | null>(null);
  
  const [isActive, setIsActive] = useState(false);
  const [logs, setLogs] = useState<string[]>(['System initialized.']);
  const [visionResult, setVisionResult] = useState<VisionAnalysisResult>({
    facialMetrics: null,
    emotionState: null,
    isTracking: false,
    fps: 0,
    error: null,
  });

  const addLog = useCallback((msg: string) => {
    setLogs(prev => [...prev.slice(-4), `[${new Date().toLocaleTimeString()}] ${msg}`]);
  }, []);

  const handleVisionResults = useCallback((landmarksResult) => {
    // Convert landmarks to facial metrics
    const facialMetrics = facialMetricsService.calculateMetrics(landmarksResult.landmarks);
    
    // Infer emotional state from facial metrics
    const emotionState = emotionInferenceService.inferEmotion(facialMetrics);
    
    setVisionResult(prev => ({
      ...prev,
      facialMetrics,
      emotionState,
      fps: visionService.getState().fps,
    }));

    // Log significant changes
    if (facialMetrics.isBlinking && Math.random() < 0.1) { // Only log some blinks to avoid spam
      addLog('Blink detected');
    }
    
    if (facialMetrics.browTension > 70) {
      addLog('High brow tension detected');
    }
    
    if (facialMetrics.mouthOpenness > 30) {
      addLog('Mouth activity detected');
    }

    // Log emotion changes
    if (emotionState.confidence > 70) {
      const explanation = emotionInferenceService.getExplanation(emotionState);
      if (Math.random() < 0.05) { // Only log occasionally to avoid spam
        addLog(`${explanation.primaryEmotion} detected (${Math.round(emotionState.confidence)}% confidence)`);
      }
    }
  }, [addLog]);

  const startCamera = async () => {
    try {
      addLog('Requesting camera access...');
      
      const stream = await navigator.mediaDevices.getUserMedia({ 
        video: { 
          width: 640, 
          height: 480,
          facingMode: 'user',
        } 
      });
      
      streamRef.current = stream;
      
      if (videoRef.current) {
        videoRef.current.srcObject = stream;
        
        // Wait for video to be ready
        await new Promise<void>((resolve) => {
          if (videoRef.current) {
            videoRef.current.onloadedmetadata = () => {
              videoRef.current?.play();
              resolve();
            };
          }
        });

        // Initialize vision service
        addLog('Initializing face tracking...');
        await visionService.initialize({
          maxFaces: 1,
          refineLandmarks: true,
          minDetectionConfidence: 0.5,
          minTrackingConfidence: 0.5,
        });

        // Set up video element and callback
        visionService.setVideoElement(videoRef.current);
        visionService.setOnResultsCallback(handleVisionResults);

        // Start tracking
        visionService.startTracking();
        
        setIsActive(true);
        addLog('Camera connected.');
        addLog('Face tracking active.');
        addLog('Analyzing facial landmarks...');
      }
    } catch (err) {
      console.error('Camera error', err);
      const errorMessage = err instanceof Error ? err.message : 'Unknown error';
      addLog(`Error: ${errorMessage}`);
      setVisionResult(prev => ({
        ...prev,
        error: errorMessage,
      }));
    }
  };

  const stopCamera = useCallback(() => {
    // Stop vision service first
    visionService.stopTracking();
    visionService.cleanup();
    
    // Stop camera stream
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
      streamRef.current = null;
    }
    
    if (videoRef.current) {
      videoRef.current.srcObject = null;
    }
    
    setIsActive(false);
    setVisionResult({
      facialMetrics: null,
      emotionState: null,
      isTracking: false,
      fps: 0,
      error: null,
    });
    
    addLog('Stream paused.');
  }, []);

  useEffect(() => {
    return () => {
      stopCamera();
    };
  }, [stopCamera]);

  // Get display values for metrics
  const getFatigueLevel = () => {
    if (!visionResult.facialMetrics) return '---';
    const fatigue = visionResult.facialMetrics.blinkRate;
    if (fatigue < 10) return 'Low';
    if (fatigue < 20) return 'Moderate';
    return 'High';
  };

  const getStressLevel = () => {
    if (!visionResult.facialMetrics) return '---';
    const tension = visionResult.facialMetrics.browTension;
    if (tension < 30) return 'Low';
    if (tension < 60) return 'Moderate';
    return 'High';
  };

  const getRestlessnessLevel = () => {
    if (!visionResult.facialMetrics) return '---';
    const restlessness = visionResult.facialMetrics.headMovementVariance;
    if (restlessness < 20) return 'Low';
    if (restlessness < 40) return 'Moderate';
    return 'High';
  };

  // Get primary emotion display
  const getPrimaryEmotion = () => {
    if (!visionResult.emotionState) return '---';
    
    const emotions = [
      { name: 'Calm', score: visionResult.emotionState.calm },
      { name: 'Anxious', score: visionResult.emotionState.anxious },
      { name: 'Stressed', score: visionResult.emotionState.stressed },
      { name: 'Neutral', score: visionResult.emotionState.neutral },
    ];
    
    const primary = emotions.reduce((prev, current) => 
      prev.score > current.score ? prev : current
    );
    
    return primary.name;
  };

  const getEmotionConfidence = () => {
    if (!visionResult.emotionState) return 0;
    return Math.round(visionResult.emotionState.confidence);
  };

  const getEmotionColor = (emotion: string) => {
    switch (emotion) {
      case 'Calm': return 'bg-cool';
      case 'Anxious': return 'bg-warmth';
      case 'Stressed': return 'bg-primary';
      case 'Neutral': return 'bg-borderDim';
      default: return 'bg-borderDim';
    }
  };

  return (
    <div className="pt-32 pb-12 px-4 max-w-5xl mx-auto bg-background transition-colors duration-500 min-h-screen">
      
      <div className="text-center mb-12">
        <h1 className="text-4xl font-serif italic text-textMain mb-4">Non-verbal Insight</h1>
        <p className="text-textSec max-w-xl mx-auto font-light">
          Aura uses local privacy-first vision processing to understand emotional cues you might miss.
        </p>
      </div>

      <div className="grid grid-cols-1 lg:grid-cols-3 gap-8">
        
        {/* Main Camera Feed */}
        <div className="lg:col-span-2 space-y-8">
          <div className="relative rounded-3xl overflow-hidden bg-surface aspect-video border border-borderDim shadow-soft ring-1 ring-black/5">
            {!isActive && (
              <div className="absolute inset-0 flex items-center justify-center flex-col gap-4 z-10 bg-surface/80 backdrop-blur-sm">
                <div className="p-5 rounded-full bg-background border border-borderDim shadow-sm">
                  <Camera className="w-8 h-8 text-textSec" strokeWidth={1.5} />
                </div>
                <p className="text-textSec font-medium">Camera inactive</p>
              </div>
            )}
            <video 
              ref={videoRef} 
              autoPlay 
              muted 
              className={`w-full h-full object-cover transform scale-x-[-1] transition-all duration-700 ${isActive ? 'opacity-100 grayscale-[20%]' : 'opacity-0'}`} 
            />
            
            {/* Soft Overlay UI */}
            {isActive && (
              <div className="absolute top-6 left-6 right-6 flex justify-between items-start">
                 <span className="px-3 py-1.5 bg-background/80 backdrop-blur-md rounded-full text-xs text-primary font-medium flex items-center gap-2 border border-borderDim">
                   <span className="w-2 h-2 rounded-full bg-primary animate-pulse" /> 
                   Active Analysis ({visionResult.fps} FPS)
                 </span>
                 {visionResult.facialMetrics && (
                   <span className="px-3 py-1.5 bg-background/80 backdrop-blur-md rounded-full text-xs text-warmth font-medium border border-borderDim">
                     {visionResult.facialMetrics.confidence > 0.7 ? 'High Confidence' : 'Tracking...'}
                   </span>
                 )}
              </div>
            )}
          </div>

          <div className="flex justify-center">
            {!isActive ? (
              <Button onClick={startCamera} className="w-full md:w-auto min-w-[200px]">
                <Play className="w-4 h-4" /> Start Session
              </Button>
            ) : (
              <Button variant="secondary" onClick={stopCamera} className="w-full md:w-auto min-w-[200px]">
                <Pause className="w-4 h-4" /> Pause
              </Button>
            )}
          </div>
        </div>

        {/* Data Panel */}
        <div className="space-y-6">
          <GlassCard className="h-full flex flex-col justify-between">
            <div>
              <h3 className="text-lg font-medium text-textMain mb-6 flex items-center gap-2">
                <Eye className="w-5 h-5 text-primary" /> Real-time Metrics
              </h3>
              
              <div className="space-y-6">
                <div className="space-y-2">
                  <div className="flex justify-between text-sm">
                    <span className="text-textSec">Eye Fatigue</span>
                    <span className="text-textMain font-medium">{getFatigueLevel()}</span>
                  </div>
                  <div className="w-full bg-borderDim h-1.5 rounded-full overflow-hidden">
                     <div 
                       className="bg-warmth h-full rounded-full transition-all duration-1000" 
                       style={{ 
                         width: visionResult.facialMetrics ? 
                           `${Math.min(100, visionResult.facialMetrics.blinkRate * 3)}%` : '0%' 